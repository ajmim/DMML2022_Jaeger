{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# CamamBERT model\n",
    "\n",
    "> CamemBERT is a state-of-the-art language model for French based on the RoBERTa architecture pretrained on the French subcorpus of the newly available multilingual corpus OSCAR.\n",
    "> https://camembert-model.fr"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "import seaborn as sns\n",
    "import torch  # GPU optim. + gradient opt.\n",
    "from torch.utils.data import DataLoader\n",
    "import functools\n",
    "from LightningModel import LightningModel\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('camembert-base') #clean, tokenize as proprecessing is required for model camambert\n",
    "\n",
    "dataset = load_dataset('Makxxx/french_CEFR') # stocked in huggingface, like a github for dataset. --> cambembert already loaded with right functions\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd_dataset = {split_name: split_data.to_pandas() for split_name, split_data in dataset.items()}\n",
    "pd_dataset[\"validation\"] #to test why we choose validation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualize data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.set_theme()\n",
    "\n",
    "nb_labels = len(pd_dataset[\"train\"][\"label\"].unique())\n",
    "print(f\"Le dataset comprend {nb_labels} labels.\")\n",
    "\n",
    "ax = pd_dataset[\"train\"][\"label\"].hist(density=True, bins=nb_labels)\n",
    "ax.set_xlabel(\"Label ID\")\n",
    "ax.set_ylabel(\"Fréquence\")\n",
    "ax.set_title(\"Répartition des labels dans le dataset (train split)\")\n",
    "ax.figure.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd_dataset[\"train\"][\"len_sen\"] = pd_dataset[\"train\"][\"sentence\"].apply(lambda x: len(x))\n",
    "ax = pd_dataset[\"train\"][\"len_sen\"].hist(density=True, bins=50)\n",
    "ax.set_xlabel(\"Longueur\")\n",
    "ax.set_ylabel(\"Fréquence\")\n",
    "ax.set_title(\"Nombre de caractères par phrase\")\n",
    "ax.figure.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd_dataset[\"train\"][\"len_sen\"].max()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### defining fuctuion batch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def tokenize_batch(samples, tokenizer):\n",
    "    text = [sample[\"sentence\"] for sample in samples]\n",
    "    labels = torch.tensor([sample[\"label\"] for sample in samples])\n",
    "    str_labels = [sample[\"difficulty\"] for sample in samples]\n",
    "    # The tokenizer handles\n",
    "    # - Tokenization (amazing right?)\n",
    "    # - Padding (adding empty tokens so that each example has the same length)\n",
    "    # - Truncation (cutting samples that are too long)\n",
    "    # - Special tokens (in CamemBERT, each sentence ends with a special token </s>)\n",
    "    # - Attention mask (a binary vector which tells the model which tokens to look at. For instance it will not compute anything if the token is a padding token)\n",
    "    tokens = tokenizer(text, padding=\"longest\", return_tensors=\"pt\")\n",
    "\n",
    "    return {\"input_ids\": tokens.input_ids, \"attention_mask\": tokens.attention_mask, \"labels\": labels, \"str_labels\": str_labels, \"sentences\": text}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### defining data sets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dataset, test_dataset, val_dataset = dataset.values()\n",
    "num_labels = len(pd_dataset[\"train\"][\"label\"].unique())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "#faire le lien entre dataset et les diff modèles. On met en place les paramètre batch et random.\n",
    "train_dataloader = DataLoader(\n",
    "    dataset[\"train\"],\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    collate_fn=functools.partial(tokenize_batch, tokenizer=tokenizer)\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    dataset[\"validation\"],\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    collate_fn=functools.partial(tokenize_batch, tokenizer=tokenizer)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "defining ligting model instance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lightning_model = LightningModel(\"camembert-base\", num_labels, lr=3e-5, weight_decay=2)\n",
    "# creation du modele au dessus\n",
    "model_checkpoint = pl.callbacks.ModelCheckpoint(monitor=\"valid/acc\", mode=\"max\")\n",
    "\n",
    "camembert_trainer = pl.Trainer(\n",
    "    max_epochs=25, #how many times iteration on dataset\n",
    "    gpus=1,\n",
    "    callbacks=[\n",
    "        pl.callbacks.EarlyStopping(monitor=\"valid/acc\", patience=4, mode=\"max\"),\n",
    "        model_checkpoint,\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "camembert_trainer.fit(lightning_model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lightning_model = LightningModel.load_from_checkpoint(checkpoint_path=model_checkpoint.best_model_path) #5\n",
    "#recover best model we found."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ID_TO_LABEL = dict(zip(range(6), ('A1', 'A2', 'B1', 'B2', 'C1', 'C2',)))\n",
    "label_names = list(ID_TO_LABEL.values())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(labels, preds, label_names):\n",
    "    confusion_norm = confusion_matrix(labels, preds.tolist(), labels=list(range(len(label_names))), normalize=\"true\")\n",
    "    confusion = confusion_matrix(labels, preds.tolist(), labels=list(range(len(label_names))))\n",
    "\n",
    "    plt.figure(figsize=(16, 14))\n",
    "    sns.heatmap(\n",
    "        confusion_norm,\n",
    "        annot=confusion,\n",
    "        cbar=False,\n",
    "        fmt=\"d\",\n",
    "        xticklabels=label_names,\n",
    "        yticklabels=label_names,\n",
    "        cmap=\"viridis\"\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "camembert_preds = camembert_trainer.predict(lightning_model, dataloaders=val_dataloader)\n",
    "camembert_preds = torch.cat(camembert_preds, -1)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_confusion_matrix(dataset[\"validation\"][\"label\"], camembert_preds, label_names)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(classification_report(dataset[\"validation\"][\"label\"], camembert_preds, target_names=label_names))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wrong_preds = camembert_preds.numpy() != np.array(dataset[\"validation\"][\"label\"])\n",
    "wrong = dataset[\"validation\"].to_pandas()[['sentence', 'difficulty']][wrong_preds]\n",
    "\n",
    "preds = pd.Series(camembert_preds.numpy())[wrong_preds].apply(lambda x: ID_TO_LABEL[x])\n",
    "wrong[\"preds\"] = preds\n",
    "wrong.columns = [\"sentence\", \"true\", \"predicted\"]\n",
    "wrong"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(\n",
    "    dataset[\"test\"],\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    collate_fn=functools.partial(tokenize_batch, tokenizer=tokenizer)\n",
    ")\n",
    "\n",
    "preds = camembert_trainer.predict(lightning_model, dataloaders=test_dataloader)\n",
    "preds = torch.cat(preds, -1) # ?\n",
    "\n",
    "test_df = dataset[\"test\"].to_pandas()\n",
    "test_df.label = preds.numpy()\n",
    "test_df.difficulty = test_df.label.apply(lambda x: label_names[x])\n",
    "test_df.index.name = 'id'\n",
    "test_df.drop(columns=[\"sentence\", \"label\"], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_df.to_csv('preds.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}